# -*- coding: utf-8 -*-
"""College Placement.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KJHtUZluupMozsQvAYYX563XPRGIB1rf
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("sumedh1507/college-student-placement")

print("Path to dataset files:", path)

import pandas as pd
import numpy as np
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error


files = os.listdir(path)
print(files)

df = pd.read_csv(os.path.join(path, 'college_student_placement_dataset.csv'))

df.head()

df.describe()

df.info()

df.dtypes

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

sns.set(style="darkgrid")
plt.figure(figsize=(10, 10))
df.select_dtypes(include=['number']).hist(bins=15, figsize=(10, 5))
plt.suptitle('Histogram of numerical features')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 5))
sns.heatmap(df.select_dtypes(include='number').corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
import seaborn as sns
import matplotlib.pyplot as plt

# Dropping the college ID
df = df.drop(columns=['College_ID'], errors='ignore')

#Encoding Catagorical columns
for col in df.select_dtypes(include=['object']).columns:
  df[col] = LabelEncoder().fit_transform(df[col].astype(str))

# Chossing the target
target_col = "Placement"
x = df.drop(columns=[target_col])
y = df[target_col]

#Spilit and scale
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)


#Models
models = {
    "Logistic Regression" : LogisticRegression(),
    "Decision Tree" : DecisionTreeClassifier(),
    "Random Forest" : RandomForestClassifier(),
    "Support Vector Machine" : SVC(),
    "K-Nearest Neighbours" : KNeighborsClassifier(),
    "XGBoost" : XGBClassifier(),
}

#Train Predict Evulate
for name, model in models.items():
  model.fit(x_train, y_train)
  y_pred = model.predict(x_test)
  acc = accuracy_score(y_test, y_pred) * 100
  print(f"{name} Accuracy: {acc:.2f}%")

#Perceptron
from sklearn.linear_model import Perceptron
clf = Perceptron(
    max_iter=1000,
    eta0=0.1,
    random_state=42,
    tol=1e-3,
    shuffle=True,
)

clf.fit(x_train, y_train)

accuracy = clf.score(x_test, y_test) * 100
print(f"Accuracy: {accuracy:.2f}")

#Tensorflow
import tensorflow as tf
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
print(x_train.shape)
print(y_train.shape)

plt.figure(figsize=(10, 5))
for i in range(10):
  plt.subplot(1, 10, i + 1)
  plt.imshow(x_train[i], cmap="gray")
  plt.axis("off")
  plt.title(str(y_train[i]))
plt.tight_layout()
plt.show()

"""Neural Netorks"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

#Loading The Data
(x_train, y_train), (x_test, y_test) = mnist.load_data()

#Normalizing the data
x_train = x_train / 255.0
x_test = x_test / 255.0

#One-hot encode the labels
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

"""***Building a small neural network***"""

model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation="relu"),
    Dense(10, activation="softmax"),
])

"""Compiling The **Model**"""

model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy"],
)

"""Traning the *model*"""

history = model.fit(x_train, y_train, epochs=15, batch_size=32, validation_data=(x_test, y_test))

"""**Evaulating the model**"""

test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {test_acc:.2f}")